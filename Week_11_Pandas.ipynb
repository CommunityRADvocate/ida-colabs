{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlUx1bRuzK9WBqusL9I+l2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CommunityRADvocate/ida-colabs/blob/main/Week_11_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data"
      ],
      "metadata": {
        "id": "JgAyViP1dg0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alCd-2SvdXOD"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many different file types your data may come in, and many ways to store and import that data.\n",
        "\n",
        "The most common format is Comma Separated Values (csv), and `pd.read_csv()` will be your go-to method for importing those.\n",
        "\n",
        "Some other file types you may encounter include:\n",
        "* JSON\n",
        "* Excel\n",
        "* Text\n",
        "\n",
        "You can find how to import any applicable file type by typing \"pandas import [file type]\" in your favorite search engine."
      ],
      "metadata": {
        "id": "B2yBi2FzdnW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The site Geeks for Geeks has some good resources that come up in search for how to access datasets in Colab from some common places on the web:\n",
        "* Kaggle -  [How to Import Kaggle Datasets Directly into Google Colab](https://www.geeksforgeeks.org/how-to-import-kaggle-datasets-directly-into-google-colab/)\n",
        "* Google Drive - [How to Load a Dataset From Google Drive to Colab](https://www.geeksforgeeks.org/how-to-load-a-dataset-from-the-google-drive-to-google-colab/)"
      ],
      "metadata": {
        "id": "KEqsZLvcEYrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've uploaded the Music & Mental Health Survey Results to a public [GitHub](https://github.com/CommunityRADvocate/ida2404-capstone/tree/main) repository, which is my preferred method when using Colab to analyze a public dataset."
      ],
      "metadata": {
        "id": "Sgf512eOFPCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assign raw data link to variable\n",
        "url = 'https://raw.githubusercontent.com/CommunityRADvocate/ida2404-capstone/main/mxmh_survey_results.csv'\n",
        "# use variable name as argument\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "nBfhUvIiAcF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration Methods"
      ],
      "metadata": {
        "id": "HT8-DYC1KulX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the first few rows of your dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Jr0o1z3cG0HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default this shows the first 5 rows, but you can add a parameter with the number of rows you'd like to view"
      ],
      "metadata": {
        "id": "E5eJM855LHKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view key pieces of information about your dataframe\n",
        "df.info()"
      ],
      "metadata": {
        "id": "4RUpfgRXKT3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical insights into numeric data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "b05KdcY6K7zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sorting\n",
        "\n",
        "[Sort values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)"
      ],
      "metadata": {
        "id": "d-pa3p0iSpOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check documentation for parameters\n",
        "df.sort_values('Age')\n",
        "# sort descending\n",
        "# permanently change the sort order\n",
        "# revert back to original sort"
      ],
      "metadata": {
        "id": "4_IwGvIILo3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting Data\n",
        "\n",
        "A common task in data analysis is selecting specific subsets of our data that meet certain conditions.\n",
        "\n",
        "You can create a boolean Series based on your condition and use it as an index to retrieve matching rows.\n",
        "\n",
        "[Indexing and selecting data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)"
      ],
      "metadata": {
        "id": "7M8zyW-VanKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select rows where Spotify is the user's primary streaming service\n",
        "spotify = df['Primary streaming service'] == 'Spotify'\n",
        "df[spotify].head()"
      ],
      "metadata": {
        "id": "mFpY3mzARx8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a tilde (~) can be prefixed to the boolean series to obtain the inversed index\n",
        "df[~spotify].head()"
      ],
      "metadata": {
        "id": "SUIXPhiXac56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You don't have to store the index in a variable"
      ],
      "metadata": {
        "id": "rEBdXzC1pFzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Fav genre'] == 'Jazz'].head()"
      ],
      "metadata": {
        "id": "Pf3mTud9pEdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the boolean Series as an index with the .loc object"
      ],
      "metadata": {
        "id": "YhJN-jKJbd-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve a subset of our data showing the age and hours per day columns of users who primarily stream on spotify\n",
        "df.loc[spotify, ['Age', 'Hours per day']]"
      ],
      "metadata": {
        "id": "HR-lZoEHa6-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use bitwise operators to compare boolean Series against each other"
      ],
      "metadata": {
        "id": "Mw-hF4R3oJng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select rows of users who primarily stream spotify and are over the age of 30\n",
        "df[spotify & (df['Age'] > 30)]"
      ],
      "metadata": {
        "id": "7WMYRjg3obDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulation\n",
        "\n",
        "You'll often need to add, remove, or otherwise modify data\n",
        "\n"
      ],
      "metadata": {
        "id": "62-_bYmNpcju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assigning values\n",
        "\n",
        "Our 'Music effects' column had some empty values. In Sheets we replaced those with 'No effect' rather than delete those rows. We can do the same with Pandas.\n"
      ],
      "metadata": {
        "id": "i1dexbA281CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the rows with missing values in column\n",
        "df[df['Music effects'].isnull()]"
      ],
      "metadata": {
        "id": "WCBdqER38bFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cannot update with chaining\n",
        "df[df['Music effects'].isnull()]['Music effects'] = 'No effect'"
      ],
      "metadata": {
        "id": "uay9Mxvp-VcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace null values in column using .loc\n",
        "df.loc[df['Music effects'].isnull(), 'Music effects'] = 'No effect'"
      ],
      "metadata": {
        "id": "YyAbCulppSiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check that the values have been updated"
      ],
      "metadata": {
        "id": "sQdW_KND_h1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding rows"
      ],
      "metadata": {
        "id": "eBcDOjkuDAPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_response = {\n",
        "    \"Timestamp\": \"5/27/2024 17:39:08\",\n",
        "    \"Age\": 32,\n",
        "    \"Primary streaming service\": \"Apple Music\",\n",
        "    \"Hours per day\": 3,\n",
        "    \"While working\": \"Yes\",\n",
        "    \"Instrumentalist\": \"Yes\",\n",
        "    \"Composer\": \"No\",\n",
        "    \"Fav genre\": \"Classical\",\n",
        "    \"Exploratory\": \"Yes\",\n",
        "    \"Foreign languages\": \"Yes\",\n",
        "    \"BPM\": 100,\n",
        "    \"Frequency [Classical]\": \"Very frequently\",\n",
        "    \"Frequency [Country]\": \"Rarely\",\n",
        "    \"Frequency [EDM]\": \"Rarely\",\n",
        "    \"Frequency [Folk]\": \"Sometimes\",\n",
        "    \"Frequency [Gospel]\": \"Never\",\n",
        "    \"Frequency [Hip hop]\": \"Sometimes\",\n",
        "    \"Frequency [Jazz]\": \"Sometimes\",\n",
        "    \"Frequency [K pop]\": \"Rarely\",\n",
        "    \"Frequency [Latin]\": \"Sometimes\",\n",
        "    \"Frequency [Lofi]\": \"Very frequently\",\n",
        "    \"Frequency [Metal]\": \"Rarely\",\n",
        "    \"Frequency [Pop]\": \"Sometimes\",\n",
        "    \"Frequency [R&B]\": \"Sometimes\",\n",
        "    \"Frequency [Rap]\": \"Sometimes\",\n",
        "    \"Frequency [Rock]\": \"Sometimes\",\n",
        "    \"Frequency [Video game music]\": \"Very frequently\",\n",
        "    \"Anxiety\": 5,\n",
        "    \"Depression\": 6,\n",
        "    \"Insomnia\": 1,\n",
        "    \"OCD\": 6,\n",
        "    \"Music effects\": \"Improve\",\n",
        "    \"Permissions\": \"I understand.\"\n",
        "  }"
      ],
      "metadata": {
        "id": "mjB7JVrNCHSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.append(new_response, ignore_index=True)"
      ],
      "metadata": {
        "id": "UTmYPgo0ibEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*As of Pandas 2.0, `.append()` is no longer supported.*\n",
        "\n",
        "You can instead use a combination of `.loc` and `len()` to add a single series to the end of your dataframe."
      ],
      "metadata": {
        "id": "RhdzywsiRCcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[len(df.index)] = pd.Series(new_response)"
      ],
      "metadata": {
        "id": "vj3i3WlrPxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the end of our dataframe with .tail()\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "95eKdetZSUQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To add multiple rows to your dataframe, consider using `pd.concat()`"
      ],
      "metadata": {
        "id": "gSjr-smb7NEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the DataFrames\n",
        "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
        "\t\t\t\t\t'B': ['B0', 'B1', 'B2', 'B3']})\n",
        "\n",
        "df1"
      ],
      "metadata": {
        "id": "dqmN-bxtS0M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
        "\t\t\t\t\t'B': ['B4', 'B5', 'B6', 'B7']})\n",
        "\n",
        "df2"
      ],
      "metadata": {
        "id": "-NzxONND74v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the dataframes\n",
        "df3 = pd.concat([df1, df2], ignore_index = True)\n",
        "df3"
      ],
      "metadata": {
        "id": "uM-LM-WP77Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Setting with Enlargement\n",
        "\n",
        "Assigning to a non-existent index key will automatically enlarge the dataframe and the row will be added.\n",
        "\n",
        "For autogenerated indexes, a popular workaround is figuring out the last used index and then incrementing it"
      ],
      "metadata": {
        "id": "YK9xcJp486h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_response = {\n",
        "    \"Timestamp\": \"5/27/2024 18:39:08\",\n",
        "    \"Age\": 50,\n",
        "    \"Primary streaming service\": \"Spotify\",\n",
        "    \"Hours per day\": 10,\n",
        "    \"While working\": \"Yes\",\n",
        "    \"Instrumentalist\": \"No\",\n",
        "    \"Composer\": \"No\",\n",
        "    \"Fav genre\": \"Rock\",\n",
        "    \"Exploratory\": \"Yes\",\n",
        "    \"Foreign languages\": \"Yes\",\n",
        "    \"BPM\": 122,\n",
        "    \"Frequency [Classical]\": \"Very frequently\",\n",
        "    \"Frequency [Country]\": \"Rarely\",\n",
        "    \"Frequency [EDM]\": \"Rarely\",\n",
        "    \"Frequency [Folk]\": \"Sometimes\",\n",
        "    \"Frequency [Gospel]\": \"Never\",\n",
        "    \"Frequency [Hip hop]\": \"Sometimes\",\n",
        "    \"Frequency [Jazz]\": \"Sometimes\",\n",
        "    \"Frequency [K pop]\": \"Rarely\",\n",
        "    \"Frequency [Latin]\": \"Sometimes\",\n",
        "    \"Frequency [Lofi]\": \"Very frequently\",\n",
        "    \"Frequency [Metal]\": \"Rarely\",\n",
        "    \"Frequency [Pop]\": \"Sometimes\",\n",
        "    \"Frequency [R&B]\": \"Sometimes\",\n",
        "    \"Frequency [Rap]\": \"Sometimes\",\n",
        "    \"Frequency [Rock]\": \"Sometimes\",\n",
        "    \"Frequency [Video game music]\": \"Very frequently\",\n",
        "    \"Anxiety\": 0,\n",
        "    \"Depression\": 2,\n",
        "    \"Insomnia\": 3,\n",
        "    \"OCD\": 0,\n",
        "    \"Music effects\": \"No effect\",\n",
        "    \"Permissions\": \"I understand.\"\n",
        "  }\n",
        "\n",
        "next_key = df.index.max() + 1\n",
        "df.loc[next_key] = new_response\n",
        "\n",
        "# check that it was added\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "jCU_s0AL8aNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding Columns\n",
        "\n",
        "Can use some of the same principles as adding rows\n",
        "\n",
        "Missing values will be set to `np.nan`\n",
        "\n",
        "We can add a calculated column with our various mental health scores using Enlargement"
      ],
      "metadata": {
        "id": "zrlVmVFs_oWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mental_scores = ['Anxiety', 'Depression', 'Insomnia', 'OCD']\n",
        "# referencing a column that doesn't exist will add it to our dataframe\n",
        "df['Mental health score'] = df[mental_scores].sum(axis=1)"
      ],
      "metadata": {
        "id": "lengvUpq_Uw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_qXn-SVMBDxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add calculated columns for average mental health scores\n",
        "df['Mental health average'] = df[mental_scores].mean(axis=1)"
      ],
      "metadata": {
        "id": "PK41Td7-mgGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Renaming columns\n",
        "\n",
        "Sometimes it makes sense to rename columns, whether to make them more human-readable or to make them easier to reference.\n",
        "\n",
        "You can do this a few different ways using the `DataFrame.rename()` method\n",
        "\n",
        "[documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)"
      ],
      "metadata": {
        "id": "es4ZB4SrLCnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "id": "Fq9t24YOW4NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = {'A': 'Primary', 'B': 'Secondary'}\n",
        "df3.rename(columns = col_names)"
      ],
      "metadata": {
        "id": "Gu2fyAx1k6KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.rename(str.lower, axis = 'columns', inplace=True)\n",
        "df3"
      ],
      "metadata": {
        "id": "IfTFTKShjydc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Deleting columns\n",
        "\n",
        "You can either use slicing to exclude specific columns, or remove them using `.drop()`"
      ],
      "metadata": {
        "id": "2GW53pWRkKqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Mental health score', 'Mental health average'], inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "M5r-RciZmCWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method can also be used to remove rows by index"
      ],
      "metadata": {
        "id": "NWbhhB_4nMDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view the end of our dataframe to get last index numbers\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "htE6N-bHnBF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([736, 737])"
      ],
      "metadata": {
        "id": "whHswXk8n4eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining Data Frames\n",
        "\n",
        "[Documentation for .merge()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)"
      ],
      "metadata": {
        "id": "VtcuZsrjrTH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/CommunityRADvocate/ida-colabs/main/data/transactions.csv'\n",
        "transactions = pd.read_csv(url, index_col=0)\n",
        "url = 'https://raw.githubusercontent.com/CommunityRADvocate/ida-colabs/main/data/requests.csv'\n",
        "requests = pd.read_csv(url, index_col=0)\n",
        "transactions.shape, requests.shape"
      ],
      "metadata": {
        "id": "3fqf1MmArWmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions.head()"
      ],
      "metadata": {
        "id": "M1RDEO88rr28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "requests.head()"
      ],
      "metadata": {
        "id": "lbr6wG0Ortw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we are calling merge on the `requests` DataFrame it is considered the left side\n",
        "successful_requests = requests.merge(\n",
        "    # And transactions is the right side\n",
        "    transactions,\n",
        "    # So now we line up columns that will make the join make sense.\n",
        "    left_on=['from_user', 'to_user', 'amount'],\n",
        "    right_on=['receiver', 'sender', 'amount']\n",
        ")\n",
        "# Let's take a look and see how we did\n",
        "successful_requests.head()"
      ],
      "metadata": {
        "id": "o4vF6QHUrvld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gather Insights"
      ],
      "metadata": {
        "id": "NE7exqJZuav3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "successful_requests.dtypes"
      ],
      "metadata": {
        "id": "I6f-CLm2ulhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert respective columns to datetime format\n",
        "successful_requests['request_date'] = pd.to_datetime(successful_requests['request_date'])\n",
        "successful_requests['sent_date'] = pd.to_datetime(successful_requests['sent_date'])\n",
        "# And now we can see they are converted\n",
        "successful_requests.dtypes"
      ],
      "metadata": {
        "id": "DKGsr-cdunRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column with elapsed time between requested and sent\n",
        "successful_requests['time_passed'] = successful_requests.sent_date - successful_requests.request_date"
      ],
      "metadata": {
        "id": "ZU2lIoJgvQ5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see 5 longest request to successful transactions\n",
        "successful_requests.sort_values(by='time_passed', ascending=False).head(5)"
      ],
      "metadata": {
        "id": "_W8RKrYkvkWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Wow! ${:,.2f} has passed through the request system in {} transactions!!!\".format(\n",
        "    successful_requests.amount.sum(),\n",
        "    len(successful_requests),\n",
        ")"
      ],
      "metadata": {
        "id": "XJvANL97voNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Duplicates\n",
        "\n",
        "[Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)"
      ],
      "metadata": {
        "id": "jME4BxTsw0E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boolean Series of records that are duplicated.\n",
        "#   Note that `keep=False` marks all that are duplicated\n",
        "dupes = requests[requests.duplicated(('from_user', 'to_user', 'amount'), keep=False)]\n",
        "# Order by requester and the date of request.\n",
        "#   Note that `request_date` in this case is a string, but this string date format sorts properly still.\n",
        "dupes.sort_values(['from_user', 'request_date'])"
      ],
      "metadata": {
        "id": "WFhUff5Pwd3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/CommunityRADvocate/ida-colabs/main/data/users.csv'\n",
        "users = pd.read_csv(url, index_col=0)"
      ],
      "metadata": {
        "id": "fVTso4Nlw5mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get our records sorted chronologically\n",
        "successful_requests.sort_values('request_date', inplace=True)\n",
        "\n",
        "# And then we'll drop dupes keeping only the last one.\n",
        "#  Note the use of the inplace keyword\n",
        "successful_requests.drop_duplicates(('from_user', 'to_user', 'amount'), keep='last', inplace=True)\n",
        "\n",
        "# Statement from previous notebook\n",
        "\"Wow! ${:,.2f} has passed through the request system in {} transactions!!!\".format(\n",
        "    successful_requests.amount.sum(),\n",
        "    len(successful_requests),\n",
        ")"
      ],
      "metadata": {
        "id": "Zz4Oiml5xbRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Locating records not found in another DF using `isin`\n",
        "\n",
        "[Documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isin.html)"
      ],
      "metadata": {
        "id": "-cuYqwW2yApn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boolean array where we check to see if the label (username)\n",
        "#   is in the `from_user` Series.\n",
        "made_request_index = users.index.isin(requests.from_user)\n",
        "# This will get us a list of all users who **have** made a request\n",
        "users[made_request_index].head()"
      ],
      "metadata": {
        "id": "Dc5XSHV_x8W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users[~made_request_index].head()"
      ],
      "metadata": {
        "id": "04oF3bWJyWj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling missing data\n",
        "\n",
        "Documentation:\n",
        "* [`Series.isna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.isna.html)\n",
        "* [`fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html)\n",
        "* [`dropna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html)\n",
        "\n",
        "We used the assign values method to fill in the Music effects fields that were empty, but we can instead use `fillna` to do the same."
      ],
      "metadata": {
        "id": "Ls7A-TQOzTSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-import dataset to undo any changes made\n",
        "url = 'https://raw.githubusercontent.com/CommunityRADvocate/ida2404-capstone/main/mxmh_survey_results.csv'\n",
        "\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "j-iMfJJ91TSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find rows with missing values in specified column\n",
        "df[df['Music effects'].isna()]"
      ],
      "metadata": {
        "id": "2NWSOfEo1T-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Music effects'].fillna('No effect', inplace=True)"
      ],
      "metadata": {
        "id": "6rhvvVu61c36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check to make sure we filled the empty values\n",
        "df[df['Music effects'].isna()]"
      ],
      "metadata": {
        "id": "5_JZt5mRQdXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There will be times when missing values can't easily be filled, and will not be useful in our analysis. For those instances, we can drop rows with missing data using `dropna()`"
      ],
      "metadata": {
        "id": "bu6pVcbMRCZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find rows with missing 'Age'\n",
        "df[df['Age'].isna()]"
      ],
      "metadata": {
        "id": "yGlvJEhbQeRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Age'], inplace=True)"
      ],
      "metadata": {
        "id": "Gk-_62bcRljm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Text\n",
        "\n",
        "[Handling strings](https://pandas.pydata.org/pandas-docs/stable/api.html#string-handling)"
      ],
      "metadata": {
        "id": "dKxHdF5pS_er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def render(md):\n",
        "    return display(Markdown(md))\n",
        "\n",
        "def make_chaos(df, sample_size, columns, fn):\n",
        "    # Keep chaos the same randomly\n",
        "    some = df.sample(sample_size, random_state=sample_size)\n",
        "    for col in columns:\n",
        "        some[col] = some[col].apply(fn)\n",
        "    # Update the original DataFrame\n",
        "    df.update(some)"
      ],
      "metadata": {
        "id": "tgX07cZGUCSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_rows = 10\n",
        "make_chaos(transactions, 42, ['sender'], lambda val: '$' + val)\n",
        "make_chaos(transactions, 88, ['receiver'], lambda val: val.upper())"
      ],
      "metadata": {
        "id": "BRT7IEQUUceu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions[transactions.sender.str.startswith('$')]"
      ],
      "metadata": {
        "id": "xFh_aBkpWkcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace '$' with an empty string\n",
        "transactions.sender = transactions.sender.str.replace('$', '')"
      ],
      "metadata": {
        "id": "LC6XeXBdWrVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changing Case\n",
        "\n",
        "Sometimes your data comes with mismatched letter casing within a column, which may cause unexpected results in your analysis."
      ],
      "metadata": {
        "id": "vnrBxDXNcHDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify rows where 'receiver' column values are uppercase\n",
        "transactions[transactions.receiver.str.isupper()]"
      ],
      "metadata": {
        "id": "d7Ot2Awtcp09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update receiver column of those rows to be lowercase\n",
        "transactions.loc[transactions.receiver.str.isupper(), 'receiver'] = transactions.receiver.str.lower()"
      ],
      "metadata": {
        "id": "e0HZUPfwc4g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of how you might want to use string methods to update column names in our survey dataset"
      ],
      "metadata": {
        "id": "PcEW5ShNdcT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.replace(' ', '_').str.replace('[', '').str.replace(']', '').str.lower().str.replace('frequency', 'fr')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "BqCjRlhgYiA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the benefit of formatting your columns in this way?"
      ],
      "metadata": {
        "id": "yHmVw4_Nu_i6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MsmZxPVUvE0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping\n",
        "\n",
        "DataFrame.groupby() [Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "[API](https://pandas.pydata.org/docs/reference/groupby.html)"
      ],
      "metadata": {
        "id": "3AJ_PtPDdtK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streaming_groups = df.groupby('primary_streaming_service')\n",
        "type(streaming_groups)"
      ],
      "metadata": {
        "id": "voStoelgaXhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# returns Series of total rows in each group\n",
        "streaming_groups.size()"
      ],
      "metadata": {
        "id": "Iz95u6Nefj-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many non missing data points in each column per group\n",
        "streaming_groups.count()"
      ],
      "metadata": {
        "id": "N_JpmAJJflWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GroupBy provides aggregate functions that are handy for quick calculations of numeric columns"
      ],
      "metadata": {
        "id": "qkvQK-KyhBkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streaming_groups.sum()"
      ],
      "metadata": {
        "id": "fQnFbMwgwRFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streaming_groups.mean(numeric_only=True)"
      ],
      "metadata": {
        "id": "2avqfUg1ibSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}